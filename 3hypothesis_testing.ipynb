{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 5: Hypothesis Testing\n",
    "\n",
    "This notebook covers three behavioral hypotheses:\n",
    "1. **Recovery vs. Inertia**: Do \"Rest Profiles\" precede \"Deep Work\" or further low-performance clusters?\n",
    "2. **Busy vs. Productive**: Can clustering distinguish between \"High-Volume / Low-Focus\" (Busywork) and \"High-Volume / High-Focus\" (Flow State)?\n",
    "3. **Weekend Bleed**: Do Work/Study profiles intrude into weekends, and is this the strongest predictor of \"Low Mood\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data with Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with cluster labels\n",
    "df = pd.read_csv('data/data_with_clusters.csv')\n",
    "\n",
    "# Ensure Date is datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Sort by date to ensure chronological order\n",
    "df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "print(f\"Loaded {len(df)} days of data\")\n",
    "print(f\"Date range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "\n",
    "# Cluster names (from clustering analysis)\n",
    "cluster_names = {\n",
    "    0: \"The Commuter Grind\",\n",
    "    1: \"The Deep Work / WFH Day\",\n",
    "    2: \"The Distracted Recovery\"\n",
    "}\n",
    "\n",
    "print(\"\\nCluster distribution:\")\n",
    "print(df['KMeans_Cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis 5.1: Recovery vs. Inertia\n",
    "\n",
    "**Hypothesis**: Do \"Rest Profiles\" (Cluster 2: The Distracted Recovery) typically precede \"Deep Work\" clusters (Cluster 1) suggesting recovery, or do they precede further low-performance clusters suggesting inertia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Rest Profile (Cluster 2) and Deep Work (Cluster 1)\n",
    "rest_cluster = 2  # The Distracted Recovery\n",
    "deep_work_cluster = 1  # The Deep Work / WFH Day\n",
    "\n",
    "# Find days in Rest Profile\n",
    "rest_days = df[df['KMeans_Cluster'] == rest_cluster].copy()\n",
    "\n",
    "# For each rest day, check the next day's cluster\n",
    "transitions = []\n",
    "\n",
    "for idx, row in rest_days.iterrows():\n",
    "    if idx < len(df) - 1:  # Make sure there's a next day\n",
    "        next_day_cluster = df.loc[idx + 1, 'KMeans_Cluster']\n",
    "        transitions.append({\n",
    "            'rest_date': row['Date'],\n",
    "            'next_date': df.loc[idx + 1, 'Date'],\n",
    "            'next_cluster': next_day_cluster,\n",
    "            'transition_type': 'Rest → Deep Work' if next_day_cluster == deep_work_cluster \n",
    "                            else ('Rest → Low Performance' if next_day_cluster == rest_cluster \n",
    "                                  else 'Rest → Other')\n",
    "        })\n",
    "\n",
    "transitions_df = pd.DataFrame(transitions)\n",
    "\n",
    "print(f\"Total Rest Profile days: {len(rest_days)}\")\n",
    "print(f\"Days with next day data: {len(transitions_df)}\")\n",
    "print(\"\\nTransition counts:\")\n",
    "print(transitions_df['transition_type'].value_counts())\n",
    "\n",
    "# Calculate proportions\n",
    "if len(transitions_df) > 0:\n",
    "    rest_to_deep_work = (transitions_df['next_cluster'] == deep_work_cluster).sum()\n",
    "    rest_to_low_perf = (transitions_df['next_cluster'] == rest_cluster).sum()\n",
    "    rest_to_other = len(transitions_df) - rest_to_deep_work - rest_to_low_perf\n",
    "    \n",
    "    print(\"\\nTransition Proportions:\")\n",
    "    print(f\"  Rest → Deep Work: {rest_to_deep_work}/{len(transitions_df)} ({rest_to_deep_work/len(transitions_df)*100:.1f}%)\")\n",
    "    print(f\"  Rest → Low Performance (Rest again): {rest_to_low_perf}/{len(transitions_df)} ({rest_to_low_perf/len(transitions_df)*100:.1f}%)\")\n",
    "    print(f\"  Rest → Other: {rest_to_other}/{len(transitions_df)} ({rest_to_other/len(transitions_df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize transitions\n",
    "transition_counts = transitions_df['transition_type'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "transition_counts.plot(kind='bar', color=['green', 'red', 'gray'])\n",
    "plt.title('Rest Profile Transitions: Recovery vs. Inertia')\n",
    "plt.xlabel('Transition Type')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=15, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical test: Chi-square test\n",
    "# Compare Rest → Deep Work vs Rest → Low Performance\n",
    "observed = [rest_to_deep_work, rest_to_low_perf]\n",
    "expected = [len(transitions_df) / 2, len(transitions_df) / 2]  # Equal probability\n",
    "\n",
    "if sum(observed) > 0:\n",
    "    chi2, p_value = stats.chisquare(observed, expected)\n",
    "    print(\"\\nChi-square test (Rest → Deep Work vs Rest → Low Performance):\")\n",
    "    print(f\"  Chi-square statistic: {chi2:.4f}\")\n",
    "    print(f\"  P-value: {p_value:.4f}\")\n",
    "    print(f\"  Interpretation: {'Significant' if p_value < 0.05 else 'Not significant'} difference (α=0.05)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis 5.2: Busy vs. Productive Distinction\n",
    "\n",
    "**Hypothesis**: Can unsupervised clustering distinguish between \"High-Volume / Low-Focus\" days (Busywork) and \"High-Volume / High-Focus\" days (Flow State) based on the ratio of Work_Hours to Distraction_Time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Work_Hours to Distraction_Time ratio\n",
    "# Convert Distraction_Time_Mins to hours for ratio\n",
    "df['Work_Distraction_Ratio'] = df['Work_Hours'] / (df['Distraction_Time_Mins'] / 60 + 0.001)  # Add small value to avoid division by zero\n",
    "\n",
    "# Define high-volume days (top 50% of Work_Hours)\n",
    "work_threshold = df['Work_Hours'].median()\n",
    "df['High_Volume'] = df['Work_Hours'] >= work_threshold\n",
    "\n",
    "# Define high-focus days (top 50% of Focus_Rating)\n",
    "focus_threshold = df['Focus_Rating'].median()\n",
    "df['High_Focus'] = df['Focus_Rating'] >= focus_threshold\n",
    "\n",
    "# Categorize days\n",
    "df['Productivity_Type'] = 'Low Volume'\n",
    "df.loc[df['High_Volume'] & ~df['High_Focus'], 'Productivity_Type'] = 'Busywork (High Volume, Low Focus)'\n",
    "df.loc[df['High_Volume'] & df['High_Focus'], 'Productivity_Type'] = 'Flow State (High Volume, High Focus)'\n",
    "df.loc[~df['High_Volume'] & df['High_Focus'], 'Productivity_Type'] = 'Low Volume, High Focus'\n",
    "\n",
    "print(\"Productivity Type Distribution:\")\n",
    "print(df['Productivity_Type'].value_counts())\n",
    "\n",
    "print(\"\\nProductivity Type by Cluster:\")\n",
    "crosstab = pd.crosstab(df['KMeans_Cluster'], df['Productivity_Type'], margins=True)\n",
    "print(crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Work_Hours vs Distraction_Time_Mins, colored by cluster and Focus_Rating\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Plot 1: Colored by cluster\n",
    "scatter1 = axes[0].scatter(df['Work_Hours'], df['Distraction_Time_Mins'], \n",
    "                          c=df['KMeans_Cluster'], cmap='viridis', \n",
    "                          s=100, alpha=0.6, edgecolors='black')\n",
    "axes[0].set_xlabel('Work Hours')\n",
    "axes[0].set_ylabel('Distraction Time (Minutes)')\n",
    "axes[0].set_title('Work Hours vs Distraction Time (Colored by Cluster)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter1, ax=axes[0], label='Cluster')\n",
    "\n",
    "# Plot 2: Colored by Focus_Rating\n",
    "scatter2 = axes[1].scatter(df['Work_Hours'], df['Distraction_Time_Mins'], \n",
    "                          c=df['Focus_Rating'], cmap='RdYlGn', \n",
    "                          s=100, alpha=0.6, edgecolors='black')\n",
    "axes[1].set_xlabel('Work Hours')\n",
    "axes[1].set_ylabel('Distraction Time (Minutes)')\n",
    "axes[1].set_title('Work Hours vs Distraction Time (Colored by Focus Rating)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter2, ax=axes[1], label='Focus Rating')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze if clusters naturally separate Busywork from Flow State\n",
    "high_volume_days = df[df['High_Volume']].copy()\n",
    "\n",
    "print(\"High-Volume Days Analysis:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total high-volume days: {len(high_volume_days)}\")\n",
    "print(\"\\nCluster distribution of high-volume days:\")\n",
    "print(high_volume_days['KMeans_Cluster'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nBusywork vs Flow State by Cluster:\")\n",
    "busywork_flow = high_volume_days.groupby('KMeans_Cluster')['Productivity_Type'].value_counts().unstack(fill_value=0)\n",
    "print(busywork_flow)\n",
    "\n",
    "# Check if clusters distinguish busywork from flow state\n",
    "if 'Busywork (High Volume, Low Focus)' in busywork_flow.columns and 'Flow State (High Volume, High Focus)' in busywork_flow.columns:\n",
    "    print(\"\\nCluster separation of Busywork vs Flow State:\")\n",
    "    for cluster_id in busywork_flow.index:\n",
    "        busywork_count = busywork_flow.loc[cluster_id, 'Busywork (High Volume, Low Focus)']\n",
    "        flow_count = busywork_flow.loc[cluster_id, 'Flow State (High Volume, High Focus)']\n",
    "        total = busywork_count + flow_count\n",
    "        if total > 0:\n",
    "            print(f\"  Cluster {cluster_id} ({cluster_names[cluster_id]}):\")\n",
    "            print(f\"    Busywork: {busywork_count}/{total} ({busywork_count/total*100:.1f}%)\")\n",
    "            print(f\"    Flow State: {flow_count}/{total} ({flow_count/total*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis 5.3: Weekend Bleed Effect\n",
    "\n",
    "**Hypothesis**: Do specific habit profiles strictly align with calendar weekends, or do \"Work/Study\" profiles significantly intrude into weekends, and is this intrusion the strongest predictor of \"Low Mood\" clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crosstab: cluster vs Is_Weekend\n",
    "crosstab_weekend = pd.crosstab(df['KMeans_Cluster'], df['Is_Weekend'], \n",
    "                               margins=True, \n",
    "                               rownames=['Cluster'], \n",
    "                               colnames=['Is Weekend'])\n",
    "\n",
    "print(\"Cluster Distribution by Weekend Status:\")\n",
    "print(crosstab_weekend)\n",
    "\n",
    "# Calculate proportions\n",
    "print(\"\\nProportions:\")\n",
    "weekend_props = pd.crosstab(df['KMeans_Cluster'], df['Is_Weekend'], normalize='index') * 100\n",
    "print(weekend_props.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Work/Study profiles (Clusters 0 and 1)\n",
    "work_study_clusters = [0, 1]  # Commuter Grind and Deep Work\n",
    "df['Work_Study_Profile'] = df['KMeans_Cluster'].isin(work_study_clusters)\n",
    "\n",
    "# Check if Work/Study profiles appear on weekends\n",
    "weekend_work_study = df[df['Is_Weekend'] & df['Work_Study_Profile']]\n",
    "\n",
    "print(f\"Total weekend days: {df['Is_Weekend'].sum()}\")\n",
    "print(f\"Weekend days with Work/Study profiles: {len(weekend_work_study)}\")\n",
    "print(f\"Proportion: {len(weekend_work_study)/df['Is_Weekend'].sum()*100:.1f}%\")\n",
    "\n",
    "print(\"\\nWeekend Work/Study Profile Breakdown:\")\n",
    "print(weekend_work_study['KMeans_Cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Low Mood (bottom 50% of Mood_Rating)\n",
    "mood_threshold = df['Mood_Rating'].median()\n",
    "df['Low_Mood'] = df['Mood_Rating'] < mood_threshold\n",
    "\n",
    "# Analyze Weekend + Work/Study intrusion vs Low Mood\n",
    "print(\"Weekend Bleed Effect Analysis:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create categories\n",
    "df['Weekend_Bleed'] = df['Is_Weekend'] & df['Work_Study_Profile']\n",
    "\n",
    "# Compare mood across different scenarios\n",
    "scenarios = {\n",
    "    'Weekday + Work/Study': (~df['Is_Weekend']) & df['Work_Study_Profile'],\n",
    "    'Weekend + Work/Study (Bleed)': df['Weekend_Bleed'],\n",
    "    'Weekend + Rest': df['Is_Weekend'] & ~df['Work_Study_Profile'],\n",
    "    'Weekday + Rest': (~df['Is_Weekend']) & ~df['Work_Study_Profile']\n",
    "}\n",
    "\n",
    "print(\"\\nMood Rating by Scenario:\")\n",
    "for scenario_name, mask in scenarios.items():\n",
    "    scenario_data = df[mask]\n",
    "    if len(scenario_data) > 0:\n",
    "        print(f\"\\n{scenario_name} (n={len(scenario_data)}):\")\n",
    "        print(f\"  Mean Mood: {scenario_data['Mood_Rating'].mean():.2f}\")\n",
    "        print(f\"  Low Mood Rate: {scenario_data['Low_Mood'].sum()}/{len(scenario_data)} ({scenario_data['Low_Mood'].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test: Compare mood between Weekend+Bleed vs Weekend+Rest\n",
    "weekend_bleed_mood = df[df['Weekend_Bleed']]['Mood_Rating'].values\n",
    "weekend_rest_mood = df[df['Is_Weekend'] & ~df['Work_Study_Profile']]['Mood_Rating'].values\n",
    "\n",
    "if len(weekend_bleed_mood) > 0 and len(weekend_rest_mood) > 0:\n",
    "    t_stat, p_value = stats.ttest_ind(weekend_bleed_mood, weekend_rest_mood)\n",
    "    \n",
    "    print(\"\\nStatistical Test: Weekend Bleed vs Weekend Rest\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Weekend + Work/Study Mood: {weekend_bleed_mood.mean():.2f} ± {weekend_bleed_mood.std():.2f}\")\n",
    "    print(f\"Weekend + Rest Mood: {weekend_rest_mood.mean():.2f} ± {weekend_rest_mood.std():.2f}\")\n",
    "    print(f\"\\nT-test:\")\n",
    "    print(f\"  T-statistic: {t_stat:.4f}\")\n",
    "    print(f\"  P-value: {p_value:.4f}\")\n",
    "    print(f\"  Interpretation: {'Significant' if p_value < 0.05 else 'Not significant'} difference (α=0.05)\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Mood by scenario\n",
    "scenario_moods = [df[mask]['Mood_Rating'].values for mask in scenarios.values()]\n",
    "axes[0].boxplot(scenario_moods, labels=list(scenarios.keys()))\n",
    "axes[0].set_ylabel('Mood Rating')\n",
    "axes[0].set_title('Mood Rating by Scenario')\n",
    "axes[0].tick_params(axis='x', rotation=15)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: Low Mood rate by scenario\n",
    "low_mood_rates = [df[mask]['Low_Mood'].mean() * 100 for mask in scenarios.values()]\n",
    "axes[1].bar(range(len(scenarios)), low_mood_rates, color=['blue', 'red', 'green', 'orange'])\n",
    "axes[1].set_xticks(range(len(scenarios)))\n",
    "axes[1].set_xticklabels(list(scenarios.keys()), rotation=15, ha='right')\n",
    "axes[1].set_ylabel('Low Mood Rate (%)')\n",
    "axes[1].set_title('Low Mood Rate by Scenario')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Hypothesis Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile summary\n",
    "print(\"=\"*80)\n",
    "print(\"HYPOTHESIS TESTING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. Recovery vs. Inertia Hypothesis:\")\n",
    "if len(transitions_df) > 0:\n",
    "    recovery_rate = rest_to_deep_work / len(transitions_df) * 100\n",
    "    inertia_rate = rest_to_low_perf / len(transitions_df) * 100\n",
    "    print(f\"   Rest → Deep Work: {recovery_rate:.1f}%\")\n",
    "    print(f\"   Rest → Low Performance: {inertia_rate:.1f}%\")\n",
    "    print(f\"   Conclusion: {'Recovery' if recovery_rate > inertia_rate else 'Inertia'} pattern dominates\")\n",
    "\n",
    "print(\"\\n2. Busy vs. Productive Distinction:\")\n",
    "print(f\"   High-volume days: {len(high_volume_days)}\")\n",
    "if 'Busywork (High Volume, Low Focus)' in df['Productivity_Type'].values:\n",
    "    busywork_count = (df['Productivity_Type'] == 'Busywork (High Volume, Low Focus)').sum()\n",
    "    flow_count = (df['Productivity_Type'] == 'Flow State (High Volume, High Focus)').sum()\n",
    "    print(f\"   Busywork days: {busywork_count}\")\n",
    "    print(f\"   Flow State days: {flow_count}\")\n",
    "\n",
    "print(\"\\n3. Weekend Bleed Effect:\")\n",
    "print(f\"   Weekend days with Work/Study profiles: {len(weekend_work_study)}/{df['Is_Weekend'].sum()} ({len(weekend_work_study)/df['Is_Weekend'].sum()*100:.1f}%)\")\n",
    "if len(weekend_bleed_mood) > 0 and len(weekend_rest_mood) > 0:\n",
    "    print(f\"   Weekend Bleed Mood: {weekend_bleed_mood.mean():.2f}\")\n",
    "    print(f\"   Weekend Rest Mood: {weekend_rest_mood.mean():.2f}\")\n",
    "    print(f\"   {'Weekend Bleed' if weekend_bleed_mood.mean() < weekend_rest_mood.mean() else 'No clear'} effect on mood\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save updated dataframe with hypothesis analysis columns\n",
    "df.to_csv('data/data_with_hypothesis_analysis.csv', index=False)\n",
    "\n",
    "# Save transitions data\n",
    "transitions_df.to_csv('data/recovery_inertia_transitions.csv', index=False)\n",
    "\n",
    "print(\"Results saved:\")\n",
    "print(\"- data/data_with_hypothesis_analysis.csv\")\n",
    "print(\"- data/recovery_inertia_transitions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
