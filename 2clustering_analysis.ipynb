{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 & 4: Clustering Analysis and Statistical Validation\n",
    "\n",
    "This notebook covers:\n",
    "- **Phase 3**: K-Means clustering with comparative analysis (Hierarchical, DBSCAN, GMM)\n",
    "- **Phase 4**: Statistical validation using ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "from scipy import stats\n",
    "from scipy.stats import f_oneway\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data and scaled features\n",
    "df = pd.read_csv('data/cleaned_data.csv')\n",
    "X_scaled = pd.read_csv('data/scaled_features.csv')\n",
    "\n",
    "# Load metadata\n",
    "with open('data/metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "clustering_features = metadata['clustering_features']\n",
    "targets = metadata['targets']\n",
    "\n",
    "print(f\"Loaded {len(df)} samples\")\n",
    "print(f\"Clustering features: {clustering_features}\")\n",
    "print(f\"Targets: {targets}\")\n",
    "\n",
    "# Convert to numpy array for sklearn\n",
    "X_scaled_array = X_scaled.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3.1: Elbow Method / Silhouette Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow Method and Silhouette Score for k selection\n",
    "k_range = range(2, 8)\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_scaled_array)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_scaled_array, kmeans.labels_))\n",
    "\n",
    "# Plot results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Elbow plot\n",
    "ax1.plot(k_range, inertias, 'bo-')\n",
    "ax1.set_xlabel('Number of Clusters (k)')\n",
    "ax1.set_ylabel('Inertia')\n",
    "ax1.set_title('Elbow Method')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Silhouette plot\n",
    "ax2.plot(k_range, silhouette_scores, 'ro-')\n",
    "ax2.set_xlabel('Number of Clusters (k)')\n",
    "ax2.set_ylabel('Silhouette Score')\n",
    "ax2.set_title('Silhouette Score')\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print scores\n",
    "print(\"Silhouette Scores:\")\n",
    "for k, score in zip(k_range, silhouette_scores):\n",
    "    print(f\"  k={k}: {score:.4f}\")\n",
    "\n",
    "# Methodology suggests k=3, validate this choice\n",
    "optimal_k = 3\n",
    "print(f\"\\nUsing k={optimal_k} (as per methodology)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3.2: Fit K-Means (k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit K-Means with k=3\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "kmeans_labels = kmeans.fit_predict(X_scaled_array)\n",
    "\n",
    "# Add cluster labels to dataframe\n",
    "df['KMeans_Cluster'] = kmeans_labels\n",
    "\n",
    "print(f\"K-Means clustering completed with k=3\")\n",
    "print(f\"Cluster distribution:\")\n",
    "print(df['KMeans_Cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3.3: Cluster Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean and std of each feature per cluster\n",
    "cluster_profiles = df.groupby('KMeans_Cluster')[clustering_features + targets].agg(['mean', 'std'])\n",
    "\n",
    "print(\"Cluster Profiles (Mean ± Std):\")\n",
    "print(cluster_profiles)\n",
    "\n",
    "# Name clusters based on characteristics (per methodology)\n",
    "cluster_names = {\n",
    "    0: \"The Commuter Grind\",\n",
    "    1: \"The Deep Work / WFH Day\",\n",
    "    2: \"The Distracted Recovery\"\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cluster Characteristics:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for cluster_id in sorted(df['KMeans_Cluster'].unique()):\n",
    "    cluster_data = df[df['KMeans_Cluster'] == cluster_id]\n",
    "    print(f\"\\n{cluster_names[cluster_id]} (Cluster {cluster_id}):\")\n",
    "    print(f\"  Count: {len(cluster_data)} days\")\n",
    "    print(f\"  Travel Time: {cluster_data['Travel Time (Hours)'].mean():.2f} ± {cluster_data['Travel Time (Hours)'].std():.2f} hours\")\n",
    "    print(f\"  Work Hours: {cluster_data['Work_Hours'].mean():.2f} ± {cluster_data['Work_Hours'].std():.2f} hours\")\n",
    "    print(f\"  Study Hours: {cluster_data['Study_Hours'].mean():.2f} ± {cluster_data['Study_Hours'].std():.2f} hours\")\n",
    "    print(f\"  Distraction Time: {cluster_data['Distraction_Time_Mins'].mean():.2f} ± {cluster_data['Distraction_Time_Mins'].std():.2f} mins\")\n",
    "    print(f\"  Sleep Hours: {cluster_data['Sleep_Hours'].mean():.2f} ± {cluster_data['Sleep_Hours'].std():.2f} hours\")\n",
    "    print(f\"  Tasks Completed: {cluster_data['Tasks_Completed'].mean():.2f} ± {cluster_data['Tasks_Completed'].std():.2f}\")\n",
    "    print(f\"  Mood Rating: {cluster_data['Mood_Rating'].mean():.2f} ± {cluster_data['Mood_Rating'].std():.2f}\")\n",
    "    print(f\"  Focus Rating: {cluster_data['Focus_Rating'].mean():.2f} ± {cluster_data['Focus_Rating'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3.4: Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA for 2D visualization\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled_array)\n",
    "\n",
    "# Create PCA dataframe\n",
    "pca_df = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])\n",
    "pca_df['Cluster'] = kmeans_labels\n",
    "pca_df['Cluster_Name'] = pca_df['Cluster'].map(cluster_names)\n",
    "\n",
    "# Plot PCA scatter\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(pca_df['PC1'], pca_df['PC2'], c=pca_df['Cluster'], \n",
    "                     cmap='viridis', s=100, alpha=0.6, edgecolors='black')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "plt.title('K-Means Clustering Results (PCA Visualization)')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.legend(handles=[plt.Line2D([0], [0], marker='o', color='w', \n",
    "                               markerfacecolor=plt.cm.viridis(i/2), \n",
    "                               markersize=10, label=cluster_names[i]) \n",
    "                    for i in range(3)])\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots of key features by cluster\n",
    "key_features = ['Travel Time (Hours)', 'Work_Hours', 'Study_Hours', \n",
    "                'Distraction_Time_Mins', 'Sleep_Hours', 'Tasks_Completed']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(key_features):\n",
    "    df.boxplot(column=feature, by='KMeans_Cluster', ax=axes[idx])\n",
    "    axes[idx].set_title(f'{feature} by Cluster')\n",
    "    axes[idx].set_xlabel('Cluster')\n",
    "    axes[idx].set_ylabel(feature)\n",
    "\n",
    "plt.suptitle('Key Features Distribution by Cluster', y=1.02, fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of cluster centroids (scaled back for interpretability)\n",
    "# Get centroids and inverse transform\n",
    "centroids_scaled = kmeans.cluster_centers_\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df[clustering_features])\n",
    "centroids_original = scaler.inverse_transform(centroids_scaled)\n",
    "\n",
    "centroids_df = pd.DataFrame(centroids_original, \n",
    "                           columns=clustering_features,\n",
    "                           index=[cluster_names[i] for i in range(3)])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(centroids_df.T, annot=True, fmt='.2f', cmap='RdYlBu_r', \n",
    "            center=0, cbar_kws={'label': 'Feature Value'})\n",
    "plt.title('Cluster Centroids (Original Scale)')\n",
    "plt.ylabel('Features')\n",
    "plt.xlabel('Clusters')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3.5: Comparative Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit alternative clustering algorithms\n",
    "k = 3\n",
    "\n",
    "# Hierarchical Clustering (Agglomerative)\n",
    "hierarchical = AgglomerativeClustering(n_clusters=k, linkage='ward')\n",
    "hierarchical_labels = hierarchical.fit_predict(X_scaled_array)\n",
    "df['Hierarchical_Cluster'] = hierarchical_labels\n",
    "\n",
    "# DBSCAN (tune eps and min_samples to get ~3 clusters)\n",
    "# Try different eps values\n",
    "eps_values = [0.5, 1.0, 1.5, 2.0, 2.5]\n",
    "best_eps = None\n",
    "best_n_clusters = 0\n",
    "\n",
    "for eps in eps_values:\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=3)\n",
    "    dbscan_labels = dbscan.fit_predict(X_scaled_array)\n",
    "    n_clusters = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\n",
    "    if abs(n_clusters - k) < abs(best_n_clusters - k):\n",
    "        best_eps = eps\n",
    "        best_n_clusters = n_clusters\n",
    "\n",
    "dbscan = DBSCAN(eps=best_eps, min_samples=3)\n",
    "dbscan_labels = dbscan.fit_predict(X_scaled_array)\n",
    "df['DBSCAN_Cluster'] = dbscan_labels\n",
    "print(f\"DBSCAN: eps={best_eps}, n_clusters={best_n_clusters}, noise points={(dbscan_labels == -1).sum()}\")\n",
    "\n",
    "# Gaussian Mixture Model\n",
    "gmm = GaussianMixture(n_components=k, random_state=42)\n",
    "gmm_labels = gmm.fit_predict(X_scaled_array)\n",
    "df['GMM_Cluster'] = gmm_labels\n",
    "\n",
    "print(\"\\nAll clustering algorithms fitted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute internal metrics for each algorithm\n",
    "algorithms = {\n",
    "    'K-Means': kmeans_labels,\n",
    "    'Hierarchical': hierarchical_labels,\n",
    "    'DBSCAN': dbscan_labels,\n",
    "    'GMM': gmm_labels\n",
    "}\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "for name, labels in algorithms.items():\n",
    "    # Skip DBSCAN if too many noise points\n",
    "    if name == 'DBSCAN' and (labels == -1).sum() > len(labels) * 0.5:\n",
    "        continue\n",
    "    \n",
    "    # Filter out noise points for DBSCAN metrics\n",
    "    if name == 'DBSCAN':\n",
    "        mask = labels != -1\n",
    "        if mask.sum() < 3:  # Need at least 3 points\n",
    "            continue\n",
    "        X_filtered = X_scaled_array[mask]\n",
    "        labels_filtered = labels[mask]\n",
    "        silhouette = silhouette_score(X_filtered, labels_filtered)\n",
    "        ch_score = calinski_harabasz_score(X_filtered, labels_filtered)\n",
    "    else:\n",
    "        silhouette = silhouette_score(X_scaled_array, labels)\n",
    "        ch_score = calinski_harabasz_score(X_scaled_array, labels)\n",
    "    \n",
    "    comparison_results.append({\n",
    "        'Algorithm': name,\n",
    "        'Silhouette Score': silhouette,\n",
    "        'Calinski-Harabasz Index': ch_score\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "print(\"Internal Metrics Comparison:\")\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 4: Statistical Validation (ANOVA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 4.1: Mood vs. Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-way ANOVA: Mood_Rating by K-Means cluster\n",
    "cluster_groups = [df[df['KMeans_Cluster'] == i]['Mood_Rating'].values \n",
    "                  for i in range(3)]\n",
    "\n",
    "f_statistic_mood, p_value_mood = f_oneway(*cluster_groups)\n",
    "\n",
    "print(\"ANOVA Results: Mood_Rating vs K-Means Cluster\")\n",
    "print(\"=\"*60)\n",
    "print(f\"F-statistic: {f_statistic_mood:.4f}\")\n",
    "print(f\"P-value: {p_value_mood:.4f}\")\n",
    "print(f\"\\nInterpretation: {'Significant' if p_value_mood < 0.05 else 'Not significant'} difference in mood across clusters (α=0.05)\")\n",
    "\n",
    "# Box plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "df.boxplot(column='Mood_Rating', by='KMeans_Cluster', ax=plt.gca())\n",
    "plt.title('Mood Rating by Cluster')\n",
    "plt.suptitle('')  # Remove default title\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Mood Rating')\n",
    "plt.xticks([1, 2, 3], [cluster_names[i] for i in range(3)], rotation=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 4.2: Focus vs. Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-way ANOVA: Focus_Rating by K-Means cluster\n",
    "cluster_groups_focus = [df[df['KMeans_Cluster'] == i]['Focus_Rating'].values \n",
    "                        for i in range(3)]\n",
    "\n",
    "f_statistic_focus, p_value_focus = f_oneway(*cluster_groups_focus)\n",
    "\n",
    "print(\"ANOVA Results: Focus_Rating vs K-Means Cluster\")\n",
    "print(\"=\"*60)\n",
    "print(f\"F-statistic: {f_statistic_focus:.4f}\")\n",
    "print(f\"P-value: {p_value_focus:.4f}\")\n",
    "print(f\"\\nInterpretation: {'Significant' if p_value_focus < 0.05 else 'Not significant'} difference in focus across clusters (α=0.05)\")\n",
    "\n",
    "# Box plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "df.boxplot(column='Focus_Rating', by='KMeans_Cluster', ax=plt.gca())\n",
    "plt.title('Focus Rating by Cluster')\n",
    "plt.suptitle('')  # Remove default title\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Focus Rating')\n",
    "plt.xticks([1, 2, 3], [cluster_names[i] for i in range(3)], rotation=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 4.3: ANOVA Comparison Across All Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ANOVA for all algorithms\n",
    "anova_results = []\n",
    "\n",
    "for name, labels in algorithms.items():\n",
    "    if name == 'DBSCAN' and (labels == -1).sum() > len(labels) * 0.5:\n",
    "        continue\n",
    "    \n",
    "    # Filter noise for DBSCAN\n",
    "    if name == 'DBSCAN':\n",
    "        mask = labels != -1\n",
    "        if mask.sum() < 3:\n",
    "            continue\n",
    "        df_filtered = df[mask].copy()\n",
    "        labels_filtered = labels[mask]\n",
    "        unique_labels = sorted([l for l in set(labels_filtered) if l != -1])\n",
    "        if len(unique_labels) < 2:\n",
    "            continue\n",
    "        groups_mood = [df_filtered[labels_filtered == i]['Mood_Rating'].values \n",
    "                      for i in unique_labels]\n",
    "        groups_focus = [df_filtered[labels_filtered == i]['Focus_Rating'].values \n",
    "                        for i in unique_labels]\n",
    "    else:\n",
    "        unique_labels = sorted(set(labels))\n",
    "        groups_mood = [df[labels == i]['Mood_Rating'].values for i in unique_labels]\n",
    "        groups_focus = [df[labels == i]['Focus_Rating'].values for i in unique_labels]\n",
    "    \n",
    "    if len(groups_mood) >= 2 and all(len(g) > 0 for g in groups_mood):\n",
    "        f_mood, p_mood = f_oneway(*groups_mood)\n",
    "    else:\n",
    "        f_mood, p_mood = np.nan, np.nan\n",
    "    \n",
    "    if len(groups_focus) >= 2 and all(len(g) > 0 for g in groups_focus):\n",
    "        f_focus, p_focus = f_oneway(*groups_focus)\n",
    "    else:\n",
    "        f_focus, p_focus = np.nan, np.nan\n",
    "    \n",
    "    anova_results.append({\n",
    "        'Algorithm': name,\n",
    "        'ANOVA Mood F-stat': f_mood,\n",
    "        'ANOVA Mood p-value': p_mood,\n",
    "        'ANOVA Focus F-stat': f_focus,\n",
    "        'ANOVA Focus p-value': p_focus\n",
    "    })\n",
    "\n",
    "anova_comparison = pd.DataFrame(anova_results)\n",
    "print(\"ANOVA Results Comparison:\")\n",
    "print(anova_comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 4.4: Post-hoc Tests (if ANOVA significant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-hoc tests using pairwise t-tests (if ANOVA is significant)\n",
    "from itertools import combinations\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "if p_value_mood < 0.05:\n",
    "    print(\"Post-hoc Tests for Mood_Rating (K-Means):\")\n",
    "    print(\"=\"*60)\n",
    "    for i, j in combinations(range(3), 2):\n",
    "        group_i = df[df['KMeans_Cluster'] == i]['Mood_Rating']\n",
    "        group_j = df[df['KMeans_Cluster'] == j]['Mood_Rating']\n",
    "        t_stat, p_val = ttest_ind(group_i, group_j)\n",
    "        print(f\"Cluster {i} vs Cluster {j}: t={t_stat:.4f}, p={p_val:.4f} {'*' if p_val < 0.05 else ''}\")\n",
    "else:\n",
    "    print(\"ANOVA for Mood_Rating not significant, skipping post-hoc tests.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "if p_value_focus < 0.05:\n",
    "    print(\"Post-hoc Tests for Focus_Rating (K-Means):\")\n",
    "    print(\"=\"*60)\n",
    "    for i, j in combinations(range(3), 2):\n",
    "        group_i = df[df['KMeans_Cluster'] == i]['Focus_Rating']\n",
    "        group_j = df[df['KMeans_Cluster'] == j]['Focus_Rating']\n",
    "        t_stat, p_val = ttest_ind(group_i, group_j)\n",
    "        print(f\"Cluster {i} vs Cluster {j}: t={t_stat:.4f}, p={p_val:.4f} {'*' if p_val < 0.05 else ''}\")\n",
    "else:\n",
    "    print(\"ANOVA for Focus_Rating not significant, skipping post-hoc tests.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe with cluster labels\n",
    "df.to_csv('data/data_with_clusters.csv', index=False)\n",
    "\n",
    "# Save comparison results\n",
    "comparison_df.to_csv('data/clustering_comparison.csv', index=False)\n",
    "anova_comparison.to_csv('data/anova_comparison.csv', index=False)\n",
    "\n",
    "print(\"Results saved:\")\n",
    "print(\"- data/data_with_clusters.csv\")\n",
    "print(\"- data/clustering_comparison.csv\")\n",
    "print(\"- data/anova_comparison.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
